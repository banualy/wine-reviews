# -*- coding: utf-8 -*-
"""wine review final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/wine-review-final-9a497500-1701-4ba0-b40a-95fa847339e1.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240822/auto/storage/goog4_request%26X-Goog-Date%3D20240822T185259Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5a440f58cf22fecb8305e8b345120c787802cafb9452bc17afa08782624bbf78c4f496928d0885f2df0779a1f3de193437471e186877ca918b67d50b91945ec270129e79ef22e6d16d0d54221c076abbd19e8f67c39c151aa12208c35c1fd78e7590ddd1cb2cd8c8f548be02a6e58c4b2170ecaff02426ebf2f591315fbf0729ddf98e392c819b00ab73c84eb81050768780ba7c9e4de892937b9ae62e220f79d29dc9ff128434339ea81618c39e1d8b2dc41efc6eaa743402534218d0cb01acb3156d0051cbf0bde3dcb1472309e7bca56308ce4e5e71c34d641ad3bd20d69e44ccf06110b09477deb4b5335343b3413d506a38b2eee0c25f36b3ee932e5694
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'wine-reviews:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1442%2F8172%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240822%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240822T185259Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D59a7dc9fa202b3f8fe1924072963663c5b4976df46ea295a751350951b81fe93adfb0483a641b6d247ab5a4110bb84d278b1e1bb1525972db76a7de5cd3d532b49a47895e400fdf96f5c954430b8bfcfed3eacba2fdf7602c49649d3c7b3b1eadb724c5dc0e463f372f3c8aea784142a6e15783772c64d4eec188d155e44d5daaef1d7b3f65e82b0739666802734936494f7a6e0f5f6813cb3693c04cb819cae1f5f79bf13a5519fa83fc18266f68064b87e9911e62a7cebd29295adcbe6368f2a679765e0a3b89f3457769a3a91a5b7382b3cf6088135a4dbff21d850e3119d730e8ea54fdb1acef1f91fa80d8b19e4fbbd97d5570ef8499a5859f3050c46fe'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import matplotlib.pyplot as plt
from textblob import TextBlob

import warnings
warnings.filterwarnings('ignore')

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

#Loading data
data=pd.read_csv("/kaggle/input/wine-reviews/winemag-data_first150k.csv")

#The first few rows of the dataset
data.head()

#I removed this column as I thought there is no meaning
data=data.drop('Unnamed: 0', axis=1)
#Shape of the dataset
print(data.shape)
data.head()

#Finding the minimum price for each unique point
min_price_per_point = data.groupby('points')['price'].mean().reset_index()
min_price_per_point.columns = ['points', 'min_price']
print(min_price_per_point)

#Seems there is a correlation between average price and points
average_price_per_point = data.groupby('points')['price'].mean()
data['price'] = data['points'].map(average_price_per_point)
data.head()

#Also I want to use region_1 column, I replaced it with average squared point per each region(when I squared it correlation increased)
data['squared_points'] = data['points'] ** 2
average_squared_points = data.groupby('region_1')['squared_points'].mean()
data['region_1'] = data['region_1'].map(average_squared_points)
data = data.drop(columns='squared_points')

#Same thing for winery column
average_points = data.groupby('winery')['points'].mean().reset_index()
average_points.columns = ['winery', 'winery_average']
data = data.merge(average_points, on='winery', how='left')
data = data.drop(columns=['winery'])
data.head()

#Count of rows with null values
print(data.isna().sum())
data.dtypes

data = data.drop(['designation', 'country', 'variety', 'province', 'region_2'], axis=1)
data = data.dropna()
print(data.shape)
data.isnull().sum()

def classify_sentiment(description):
    blob = TextBlob(description)
    polarity = blob.sentiment.polarity
    return polarity
data['description'] = data['description'].apply(classify_sentiment)
data.head(10)

# Assuming `data` is your DataFrame
print(data.describe())
print(data.corr())

# Plotting correlations
plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.show()

sns.pairplot(data)

import tensorflow as tf
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Define features and target
X = data.drop(['points'], axis=1)
y = data['points']

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
X_scaled

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=4)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
print(f'Root mean Squared Error: {rmse}')
print(f'R^2 Score: {r2}')